---
3title: 面试篇（五）：中间件
date: 2019-05-28 11:15:23
categories: 面试
---

#### `Redis`

`Redis`是一个基于内存且支持持久化的`Key-Value`的`NoSQL`数据库

`Redis`支持五种数据类型：`String`（字符串）、`Hash`（哈希）、`List`（列表）、`Set`（集合）、`Sorted Set`（有序集合）

###### `Redis`与`Memcached`的区别

- `Redis`支持更丰富的数据类型（支持更复杂的应用场景）：`Redis`不仅支持简单的`Key-Value`类型的数据，同时还提供了`List`、`Set`、`Sorted Set`、`Hash`等数据结构的存储，而`Memcached`只支持简单的数据类型`String`；
- `Redis`支持数据持久化，可以将内存中的数据保存到磁盘中，重启的时候可以再次加载进行运用，而`Memcached`把数据全部存放在内存之中；
- `Redis`使用单线程IO复用模型，而`Memcached`是多线程，非租塞IO复用模型；
- `Redis`单个Value的最大限制是`1GB`，而`Memcached`是`1MB`；
- `Redis`速度比`Memcached`快。

###### `Redis`持久化机制

`Redis`支持两种不同的持久化操作：快照（`snapshotting`，`RDB`）、只追加文件（`append-only-file`，`AOF`）。

快照是默认的持久化方式。这种方式就是将内存中的数据以快照的方式写入到二进制文件中，默认文件名为`dump.rdb`。可以通过配置设置自动做快照持久化的方式，我们可以配置`Redis`在`N`秒内超过`M`个`Key`被修改就自动做快照，下面是默认的快照保存配置：

```
 save 900 1     #900秒内如果超过1个key被修改，则发起快照保存
 save 300 10    #300秒内容如超过10个key被修改，则发起快照保存
 save 60 10000  #60秒内容如超过10000个key被修改，则发起快照保存
```

与快照持久化相比，`AOF`持久化的实时性会更好，默认情况下`Redis`没有开启`AOF`方式的持久化，可以通过`appendonly`参数开启：

```
appendonly yes
```

开启`AOF`持久化后每条执行一条会更改`Redis`中的数据的命令，`Redis`就会将该命令写入硬盘中的`AOF`文件。`AOF`文件和`RDB`文件的保存位置相同，都是通过`dir`参数设置的，默认文件名是`appendonly.aof`。

在`Redis`的配置文件中存在三种不同的`AOF`持久化方式，如下：

```
appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度
appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘
appendfsync no        #让操作系统决定何时进行同步
```

为了兼顾数据和写入性能，用户可以考虑`appendfsync everysec`选项 ，让`Redis`每秒同步一次`AOF`文件，`Redis`性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，`Redis`还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。

**注意：**`AOF`重写可以产生一个新的`AOF`文件，这个新的`AOF`文件和原有的`AOF`文件保存的数据库状态一致，但体积更小。

在执行 `BGREWRITEAOF `命令时，`Redis `服务器会维护一个 `AOF `重写缓冲区，该缓冲区会在子进程创建新 `AOF `文件期间，记录服务器执行的所有写命令。当子进程完成创建新 `AOF `文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 `AOF `文件的末尾，使得新旧两个 `AOF `文件所保存的数据库状态一致。最后，服务器用新的 `AOF `文件替换旧的 `AOF `文件，以此来完成 `AOF `文件重写操作。

######  `Redis`内存回收策略（惰性删除+定期删除+内存溢出控制策略）

惰性删除：当客户端读取带有超时属性的键时，如果已经超过键设置的过期时间，会执行删除操作并返回为空。

定期删除：`Redis`内部维护了一个定时任务，默认每秒10次，根据键的过期比例、使用快慢两种速率模式回收键。

内存溢出控制策略：当`Redis`所用的内存达到最大内存上限时会触发相应溢出控制策略。具体策略受`maxmemory-policy`参数控制，`Redis`支持以下6种策略：【LRU算法（最近最少使用）】

|  策略类型  | 说明 |
| ------------ | -------------------------- |
| noeviction   | 默认，不删除键，只返回错误 |
| volatile-lru | 使用LRU算法删除一个键（只对设置了过期时间的键）|
| allkeys-lru | 常用，使用LRU算法删除一个键 |
| volatile-random | 随机删除一个键（只对设置了过期时间的键） |
| allkeys-random | 随机删除一个键 |
| volatile-ttl | 删除过期时间最近的一个键 |

###### `Redis`缓存雪崩与缓存穿透的解决方案

缓存雪崩：当缓存服务器重启或大量缓存集中在某一个时间段失效，后面的请求都会落在数据库上，造成数据库短时间内承受大量请求而奔溃。

解决方案：①对于并发量不高时，可采用加锁排队，加锁排队只是为了减轻数据库的压力，并没有提高系统吞吐量；②不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。

缓存穿透：恶意请求缓存中不存在的数据，导致所有的请求都落在数据库上，导致数据库短时间内承受大量的请求而崩掉。

解决方案：①最常见的采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。②对查询结果为空的情况也进行缓存，但缓存时间要设置短一点。

#### 消息队列

`JMS（Java Message Service） API`是一个消息服务的标准或者规范。`ActiveMq`就是基于`JMS`规范实现的。支持两种消息模型：点对点模型（`P2P`）、发布/订阅模型（`PUB/SUB`）。

- 点对点模型

  使用队列（`Queue`）作为消息通信的载体，满足生产者与消费者模式，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。

- 发布/订阅模型

  使用主题（`Topic`）作为消息通信的载体，类似于广播模式，发布者发布一条消息，该消息通过主题传递给所有的订阅者，在一条消息广播之后才订阅的用户则是收不到该条消息的。



`AMQP（Advanced Message Queuing Protocol）`是一个提供统一消息服务的应用层标准高级消息队列协议（二进制应用层协议），是应用层协议的一个开放标准，为面向消息的中间件设计，兼容`JMS`。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件同产品，不同的开发语言等条件的限制。`RabbitMQ`就是基于`AMQP`协议实现的。

###### `JMS`与`AMQP`对比

- `AMQP`为消息定义了线路层的协议，而`JMS`所定义的是`API`规范。在`Java`体系中，多个client均可通过`JMS`进行交互，不需要修改任何代码，但对跨平台的支持较差，而`AMQP`天然具有跨平台、跨语言特性；
- `JMS`支持`TextMessage、MapMessage`等复杂的消息类型，而`AMQP`仅支持二进制消息类型；
- 由于`EXchange`提供的路由算法，`AMQP`可提供多样化的路由方式传递消息到消息队列，而`JMS`只支持队列和发布/订阅方式。

###### 消息顺序消费的解决方案

- 发送端保证发送的消息有序，且发送到同一队列；
- 消费端保证消费同一队列。

###### 消息重复消费的解决方案

重复发送：`MQ`系统内部生成一个`inner-msg-id`（与业务无关）

重复消费：生成一个唯一ID标记每条消息，每次消费消息时用该ID先判断该消息是否已消费过

#### `Zookeeper`

`Zookeeper`是一个开放源码的分布式协调服务，它是集群的管理者，监视着集群中各个节点的状态。

`Zookeeper`是一个典型的分布式数据一致性解决方案，分布式应用程序可以基于`Zookeeper`实现数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列等功能。

`Zookeeper`最常用的使用场景就是用于担任服务生产者和服务消费者的注册中心（提供发布/订阅服务）。服务生产者将自己提供的服务注册到`Zookeeper`中心，服务消费者在进行服务调用的时候先到`Zookeeper`中查找服务，获取到服务生产的详细信息后，再去调用服务生产者的内容和数据，如下所示，在`Dubbo`架构中`Zookeeper`就担任注册中心这一角色。

###### `Zookeeper`中的各种角色

| 角色               | 说明                                                         |
| ------------------ | ------------------------------------------------------------ |
| 领导者（Leader）   | 负责进行投票的发起和决议，跟新系统状态                       |
| 跟随者（Follower） | 用于接受客户端请求并向客户端返回结果，在选举工程中参与投票   |
| 观察者（Observer） | 可以接受客户端连接，将写请求转发给Leader节点。但Observer不参加投票过程，只同步Leader的状态。Observer的目的是为了扩展系统，提高读取速度。 |
| 客户端（Client）   | 请求发起方                                                   |

###### `Zookeeper与客户端`

![](E:\文档\知识点\images\Zookeeper与客户端.png)

其中每个Server在工作工程中有三种状态：

- LOOKING：当前Server不知道Leader是谁，正在搜寻
- LEADING：当前Server即为选举出来的Leader
- FOLLOWING：Leader已经选举出来，当前Server与之同步

###### `ZAB`协议

`ZAB`协议是分布式协调服务`Zookeeper`专门设计的一种支持崩溃恢复的原子广播协议。

在 `ZooKeeper` 中，主要依赖 `ZAB `协议来实现分布式数据一致性，基于该协议，`ZooKeeper `实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。

`ZAB`协议有两种基本模式：崩溃恢复模式（选主）和原子广播模式（同步）。

- 当服务启动或者领导者崩溃后，`ZAB`就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和Leader的状态同步以后，恢复模式结束。状态同步保证了 leader 和 follower 之间具有相同的系统状态。
- 当 `ZooKeeper `集群选举出 leader 同步完状态退出恢复模式之后，便进入了原子广播模式。 所有的写请求都被转发给 leader，再由 leader 将更新 proposal 广播给 follower。

为了保证事务的顺序一致性，`Zookeeper`采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上了zxid。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个新的epoch，标识当前属于那个leader的统治时期。低32位用于递增计数。

###### 选主流程

当Leader崩溃或者Leader失去大多数的Follower，这时候`Zookeeper`进入恢复模式，恢复模式需要重新选举出一个新的Leader，让所有的Server都恢复到一个正确的状态。`Zookeeper`的选举算法有两种：一种是基于`Basic Paxos（Google Chubby采用）`实现的，另一种是基于`Fast Paxos（Zookeeper采用）`算法实现的。系统默认的选举算法为`Fast Paxos`。并且`Zookeeper`在3.4.0版本后只保留了`FastLeaderElection `算法。

1. `Basic Paxos`算法

2. `Fast Paxos`算法

   某个Server首先向所有的Server提议自己要成为Leader，当其他Server收到提议以后，解决epoch和zkid的冲突，并接受对方的提议，然后向对方发送接收提议完成的消息，重复这个流程，最后一定能选举出Leader。

###### 为什么最好使用奇数台服务器构成`Zookeeper`集群？

Leader选举算法采用了`Paxos`协议，`Paxos`核心思想：当多数Server写成功，则任务数据写成功如果有3个Server，则两个写成功即可；如果有4或5个Server，则三个写成功即可。Server数目一般为奇数（3、5、7）如果有3个Server，则最多允许1个Server挂掉；如果有4个Server，则同样最多允许1个Server挂掉由此， 我们看出3台服务器和4台服务器的的容灾能力是一样的，所以为了节省服务器资源，一般我们采用奇数个数，作为服务器部署个数。

```
注意：在Zookeeper中，node可以分为持久节点和临时节点两类。所谓持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在Zookeeper上。而临时节点就不一样了，它的生命周期与客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。
```

#### `Dubbbo`

`Dubbo`是阿里巴巴开源的基于Java的高性能`RPC`分布式服务框架，现已成为`Apache`基金会孵化项目。

###### `Dubbo`与`Spring Cloud`的区别

- 通信方式：`Dubbo`使用的是`RPC`通信，而`Spring Cloud`使用的是`Http RestFul`方式

- 组成部分

  | 组件       | Dubbo         | Spring Cloud                 |
  | ---------- | ------------- | ---------------------------- |
  | 服务中心   | Zookeeper     | Spring Cloud Netflix Eureka  |
  | 服务监控   | Dubbo-monitor | Spring Boot Admin            |
  | 断路器     | 不完善        | Spring Cloud Netflix Hystrix |
  | 服务网关   | 无            | Spring Cloud Netflix GateWay |
  | 分布式配置 | 无            | Spring Cloud Config          |
  | 服务跟踪   | 无            | Spring Cloud Sleuth          |
  | 服务总线   | 无            | Spring Cloud Bus             |
  | 数据流     | 无            | Spring Cloud Stream          |
  | 批量任务   | 无            | Spring Cloud Task            |



###### `Dubbo`支持的协议类型

`dubbo`、`rmi`、`hession`、`http`、`webservice`、`thrift`、`memcached`、`redis`、`rest`等9种协议类型。

###### `Dubbo`节点角色

| 节点      | 角色说明                               |
| --------- | -------------------------------------- |
| Provider  | 暴露服务的服务提供者                   |
| Consumer  | 调用远程服务的服务消费者               |
| Register  | 服务注册与服务发现的注册中心           |
| Monitor   | 统计服务的调用次数和调用时间的监控中心 |
| Container | 服务云心容器                           |

###### `Dubbo`集群容错

| 集群容错方案      | 说明                                       |
| ----------------- | ------------------------------------------ |
| Failover Cluster  | 默认，失败自动切换，自动重试其它服务器     |
| Failfast Cluster  | 快速失败，立即报错，只发起一次调用         |
| Failsafe Cluster  | 失败安全，出现异常时，直接忽略             |
| Failback Cluster  | 失败自动恢复，记录失败请求，定时重发       |
| Forking Cluster   | 并行调用多个服务器，只要一个成功即返回     |
| Broadcast Cluster | 广播逐个调用所有提供者，任意一个报错则报错 |

###### `Dubbo`负载均衡策略

| 负载均衡策略               | 说明                                         |
| -------------------------- | -------------------------------------------- |
| Random LoadBalance         | 默认，随机，按权重设置随机概率               |
| RandomRobin LoadBalance    | 轮询，按公约后的权重设置轮询比率             |
| LeastActive LoadBalance    | 最少活跃度调用数，相同活跃数的随机           |
| ConsistentHash LoadBalance | 一致性Hash，相同参数的请求总是发到同一提供者 |

######  `Dubbo`在安全机制方面是如何解决的？

`Dubbo`通过`Token`令牌防止用户绕过注册中心直连，然后在注册中心上管理授权。`Dubbo`还提供服务黑白名单来控制服务所允许的调用方。

###### 服务提供者实现失效踢出是什么原理？

基于`Zookeeper`的临时节点原理

###### 服务上线怎么不影响旧版本？

采用多版本开发

###### 如何解决服务调用链过长的问题？

可以结合`zipkin`实现分布式服务追踪

###### `Dubbo`的核心配置

`dubbo:service/、dubbo:reference/、dubbo:registry/、dubbo:application/、dubbo:provider/、dubbo:consumer/、dubbo:method`

```
1. Dubbo不需要Web容器，若果硬要Web容器，只会增加复杂性，也浪费资源。
2. Dubbo内置了3种服务容器：Spring Container、Jetty Container、Log4j Container，Dubbo的服务容器只是一个简单的main方法，并加载了一个简单的Spring容器，用于暴露服务。
3. Dubbo官方推荐使用Zookeeper作为注册中心，也可以使用Redis、Multicast、Simple，但不推荐。
4. Dubbo默认采用Hessian序列化，还有FastJson、Java自带序列化。
5. Dubbo默认使用NIO Netty框架。
注意：
	监控中心宕掉不影响使用，只是丢失部分采样数据；
	数据库宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务；
	注册中心对等集群，任意一台宕掉，会自动切换到另一台；
	注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存通讯；
	服务提供者无状态，任意一台宕掉后，不影响使用；
	服务提供者全部宕掉后，服务消费者应用无法使用，并无限次重连等待服务提供者恢复。
```

